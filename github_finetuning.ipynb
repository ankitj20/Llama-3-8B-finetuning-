{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk-cD9W33vUL"
   },
   "source": [
    "In this project, we are going to fine tune the Llama 3 8b model to increase it's reasoning capability on complex maths problem. We will use MetaMathQA-40k dataset to finetune model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akytWVoW3sg_",
    "outputId": "a8ba8183-fb4d-4730-bc04-637b0a356ed4"
   },
   "outputs": [],
   "source": [
    "!pip install unsloth # we will use unsloth, because of it's optimizations, also it is better to buy 100 compute units from colab, because the dataset used has 40k problems, which will be very heavy for free version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "80965ba3de9444249884f488650dc516",
      "7796d29a533c44c0918edb3a8151260c",
      "c210d2851baa49398454bd408600a928",
      "790eeb3db8c84d86a229025653ea9e01",
      "9165fc62460540de9f017d604c783598",
      "298a4fed21634c09bc8b689305e44ff5",
      "2896ad34796a42aabb46398756b1117e",
      "2dbe620b9c0946af853e21d7a6920852",
      "1ccf59d11a0a435880a971fcc1fc3516",
      "fc1537bb0d4f43fb814d21ffcbbf98f2",
      "cc3565f15a4747ca8b8f77a40d77b7d2",
      "eb03182e46844995a20dec1293dcf5ff",
      "4ecec48a568f4bf4ae99dee57c383435",
      "01e34fd0c0da4b078ecb1d43f8a92584",
      "f596f0ea7bfb41c98360cafdbb829472",
      "95495c42aff141908c23453b941a9260",
      "f43e84ee65d64292b8736a364a0d7154",
      "62203f0525414321b39426c8d99c26cf",
      "c43d1050a26245ae9018d39d666cfa60",
      "48ef0dd24dba4ad99d2a5d3a9f4b876e"
     ]
    },
    "id": "ZnhQkCZ_keP2",
    "outputId": "d60d3eb1-01f4-4635-9d1c-3c65c11ba755"
   },
   "outputs": [],
   "source": [
    "# You need to have a hugging face account and approval to use Llama models before proceeding\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFWwsMgH_RIo",
    "outputId": "573ff8bf-9175-490f-8a30-1936916e80e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3DZayS3_snr"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 2048\n",
    "load_in_4bit = True # 4-bit QLoRA quantization\n",
    "dtype = None # Setting it to none, it let the gpu figure out data type will be the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298,
     "referenced_widgets": [
      "6a2b1c35967b41abacb7c9e98897eba0",
      "b50202f7ef9b45eeaf4f56f1037c623c",
      "2b8cbf1b59d24ad3bdee680e1b50bab3",
      "bd31a319e07e4bfba893e1f884f32990",
      "8b50ba58db9d452ca8e5ead8adfe6061",
      "8138ea786ae04df2b15190c7989aec1e",
      "5aef7b16c83f4ba5bfe9977c7488e514",
      "898edde29b134e16829ea7d45eca4da9",
      "618cffa23b814f83ac4b5400706bd49f",
      "2fbd263b507649cc965f31244fad4747",
      "72c01ac7626d422da022f988bdc21066",
      "cc4245179e95428abee2664e34a81502",
      "a5c9227c98694d2ea1d2c1231999dbd4",
      "0b72b1e29367450a9236c57fddb46cb8",
      "e7f526a3ec6548568e367a45c57bad84",
      "deb17788c66b4dc397112b41273c5755",
      "b524fd3826fb4facae56487e6998f2dd",
      "5d983fbca91a4fa0a4ab75a8f3a45760",
      "ff2f712d03b6405db4af05c3bbab6019",
      "cabb0088585540ee974f176c350b5f4e",
      "95834a060de94ce982ce0d118d302cb7",
      "1fdd47396612470db04675acd3a0885d",
      "7882e9016adb4153a5d0286aa8262047",
      "8bfc5f67992e4f98aec2226f2c5c7e62",
      "e9663c0673bc489a820d42cc6356de8d",
      "1130ba6499fe4224bef4e257d359d5e4",
      "bb2aa04a61d5454aad80b3e7392f0d63",
      "a15e49732640441b889beed639e5eed2",
      "35b5043ff42643e192e7f04deb242762",
      "a3816c2131664799867d72dd22235f53",
      "1fbd79a05097456284b51bdd8798d4c0",
      "b087305d198642b0b37f3dfd79b691d7",
      "592c0ca0b8be4515861632ebd2592d56",
      "52bb8f7718184c8f8cd0190477506edb",
      "9ebaa967c19b43d988ed749efaa278a5",
      "4d99bafd7d1d46c58f57de45d841627c",
      "b694a2b124e84551a7f7b981093cefdb",
      "1a85c75d0dc9472ea9424d8d3e434768",
      "a2e9cff3a295449d82ecf1eddbcdef11",
      "19f95de9b1d249b69a8980b14e12f405",
      "8fc748d62040471baaa12bbfcf2a799c",
      "aa830dbd173e4db2b1b2089bf614de39",
      "946c27d8d7754913967cfdc5bcc2bf57",
      "7456f7abd6d84db1b17e215186af79a6",
      "bab4d321bb2a48b58f1ca449410d65c3",
      "199af5bddf90474d8db8699d74611585",
      "a6b0ba6dc3a04cabb6d2f30111713d42",
      "e9139f48befa446daf3721c8cb1da6d2",
      "47bbbf9fc11446509113baffafb3f88f",
      "108bef0855424ef38c741d5e0cc922af",
      "dc137716832d4e94903defe4bbc696e5",
      "6958507078d748eeb983cea2137eec5a",
      "a8a652b33b4b4e38815b0c09c897d8de",
      "5f4f80353328409ab205a55e921ff4a0",
      "641d122f86064dc5941f31a4d4aa3b15"
     ]
    },
    "id": "jVDbkgMkfoEe",
    "outputId": "178c53ea-ccd3-410c-ef36-bae6c54dce7f"
   },
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "print(\"The model is loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKPVqhpgIIol"
   },
   "source": [
    "Now, we will load the dataset and format it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185,
     "referenced_widgets": [
      "2a57105d3b3f4cb098cfac27825ff51f",
      "10eb138ffa5a4408a80c72d62d2dfb48",
      "3f744f5af53c4e5192dddf5882e9e20a",
      "fbda04bf860c44c79db9a0d9a88d3490",
      "5ff56a7dfe8a44659016aafce5898830",
      "07f2fa797af04377924ceffd5cbfe939",
      "81545ca95ee94a2db39a645c817e8df9",
      "ef871a20f0ef42baa1bb7720fea63f8d",
      "8eaec8d7767540639f7f992992fbf36a",
      "7087eef391f74e1f8bb57da8ed671cb3",
      "55cbd39fcdc74674bc833a7ba80641e5",
      "10668228873e48fea736db37471b3a30",
      "17a5a63335b3490eab7852bb8886bb96",
      "e51f27d4654642ac9d50e3d5a085b03b",
      "ae41d30fdf344bb9a42d6d786e6a90ae",
      "edc0fd95941a466ebca46ac5a16c6a16",
      "5a1c04c5c0e74a2a910fd06bc92c8133",
      "f36f8ec4ec8545ec9fac54327c79add8",
      "2358510fdef546d38f28c8f8280ff92a",
      "f31c2f1a7a1149148c897372348870cc",
      "e5ee0dcd6cd64ff2b629871d1aa9f081",
      "4df5260ed5a94f87a316d1ae01813cca",
      "a17f3affd12649ceb076c56630b3388d",
      "498a410709c44a849cd0686802e28433",
      "a2a2b3e599624f65bed8903337570852",
      "d2338508210643b1ad446ece353fe6de",
      "bae017f45c444daca445762d17a75eb1",
      "0b5d9deafaad4680a2a46fbb59044522",
      "c1d1ce87aa49484e91d001071a338c2a",
      "bee60cace8874cfaa211550963bfdb16",
      "92cded2c1aa240b3b2580c84d8dfde5a",
      "4f5a9d1d3c8e42f6bef85a6336bc0f44",
      "991d775dc25d48b5a3344a66640fc55e"
     ]
    },
    "id": "QW6fVMGbBWzs",
    "outputId": "52b822aa-a33d-43db-ac02-a56890c32c4a"
   },
   "outputs": [],
   "source": [
    "# Loading the MetaMathQA-40K datset\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"meta-math/MetaMathQA-40K\", split = \"train\")\n",
    "print(len(dataset))\n",
    "print(dataset[0])\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538,
     "referenced_widgets": [
      "124da796a48e4241b5b345ed21889aab",
      "33bb9a328d714c69a81429d7c4f4d42b",
      "3c2948b4b5434c8b845537721a805d9f",
      "6d82cda137584b839a0e90fa6218282a",
      "432bbaffd6dd47e2ba222c3a6a91e056",
      "7556cde054ea4eb0936bdd4c005f3395",
      "d32f9a23b0e143e3a76096097e840760",
      "78489d58cfa34719af6c93892da53e77",
      "c37a860b54f44e249bd2354808da2d89",
      "698ce73132734dca890488918c65d8e4",
      "e8765028c16746459ef546f3bc1fba89"
     ]
    },
    "id": "rglkGBX8q4Yb",
    "outputId": "204efaff-62fd-45fa-f865-a08452ffad6a"
   },
   "outputs": [],
   "source": [
    "math_prompt = \"\"\"Act like an expert mathematician. Your task is to solve the following math problem.\n",
    "Provide a step-by-step reasoning process before arriving at the final answer.\n",
    "\n",
    "### Problem:\n",
    "{}\n",
    "\n",
    "### Answer:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def format_prompts(x):\n",
    "    instructions = x[\"query\"]\n",
    "    responses = x[\"response\"]\n",
    "    texts = []\n",
    "    for instruction, response in zip(instructions, responses):\n",
    "        text = math_prompt.format(instruction, response) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts }\n",
    "\n",
    "dataset = dataset.map(format_prompts, batched = True)\n",
    "\n",
    "print(len(dataset))\n",
    "print(dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf_e5qfuIQn5"
   },
   "source": [
    "Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3QAqNMdFiNe",
    "outputId": "5a9c369e-ea1c-4ddb-ee55-636ef47721f7"
   },
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16, # It will assign more weight to LoRA activations\n",
    "    # we choose 0 and none because of optimizations\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b14d0f3883474779ad0aafd564b7671d",
      "bf79e2619fdc48159d5daae3b76921ba",
      "d90865cbaecc4a78b1f85abde0fd4af9",
      "dc306afabadf4454a9790b4fe40f94df",
      "8f1c38919e7d46b3bd7510f2361ad959",
      "ae578facfc3b43b390ccd38ab9abbd62",
      "92884219c74b4867967bdad98dbc5ba2",
      "0f4c30d695f74ef7a4e83dd00deedb16",
      "d80e2cc942c943219c1fdbde831c0c03",
      "a9441794b52d493f86d8d57801e1f65c",
      "a86ac3de512b42719ea4c0c6eaed85bf"
     ]
    },
    "id": "CjCswY2MJvcP",
    "outputId": "8a57d08f-ae36-45dc-ce87-d11433fe383a"
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 2048,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        num_train_epochs = 1,\n",
    "        warmup_steps = 100,\n",
    "        learning_rate = 2e-4,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        optim = \"adamw_8bit\",\n",
    "\n",
    "        weight_decay = 0.01,\n",
    "        max_grad_norm = 1.0,\n",
    "        logging_steps = 50,\n",
    "        seed = 3407,\n",
    "        output_dir = \"math_llama3_8b_final\",\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-E-an91aK5IK",
    "outputId": "5e709d57-913a-46ee-be71-26d337aa585b"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrLQTxRm3L5B"
   },
   "source": [
    "To download the model locally\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T50ZrQGtGNhF",
    "outputId": "5a71b5ee-594e-4214-a105-806bda10be8a"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"math_llama3_8b_adapters\")\n",
    "tokenizer.save_pretrained(\"math_llama3_8b_adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGrhDViVFtdF",
    "outputId": "4107a43b-79c1-46ef-c289-ab9035ffcc5c"
   },
   "outputs": [],
   "source": [
    "!zip -r math_llama3_8b_adapters.zip math_llama3_8b_adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yB4XJH6YGfwX"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('math_llama3_8b_adapters.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEixcBasCD0w"
   },
   "source": [
    "To upload the model, first upload the zip file on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyfekSheCDT6",
    "outputId": "2835ae99-0ecd-49a3-a1f2-affcf8eb1dc0"
   },
   "outputs": [],
   "source": [
    "!unzip -o math_llama3_8b_adapters.zip -d math_llama3_8b_adapters_unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJ0S6FC-CVmh"
   },
   "outputs": [],
   "source": [
    "!mv math_llama3_8b_adapters_unzipped/math_llama3_8b_adapters ./math_llama3_8b_adapters_ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnnQ_6hZ4Ofy"
   },
   "source": [
    "Now, let us try running benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMfkyNFrGjyO",
    "outputId": "ce523146-19a4-4d93-e9bf-1f2a748a8e9c"
   },
   "outputs": [],
   "source": [
    "!pip install lm-eval==0.4.2\n",
    "!pip install antlr4-python3-runtime==4.11\n",
    "\n",
    "#here is the list of benchmarks available on lm-eval\n",
    "!lm-eval --tasks list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L19Ib3Q0FTON"
   },
   "source": [
    "First we will run benchmarks on base llama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1DEln4QFDpA",
    "outputId": "69c60090-1df4-4aa4-cb18-a6eada1a6a0f"
   },
   "outputs": [],
   "source": [
    "# to run benchmarks, you will need a read only type token from hugging face, first get that token and again login using that\n",
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=\"meta-llama/Meta-Llama-3-8B-Instruct\",load_in_4bit=True,trust_remote_code=True \\\n",
    "    --tasks gsm8k,minerva_math_algebra,minerva_math_geometry,minerva_math_prealgebra,asdiv \\\n",
    "    --batch_size 1 \\\n",
    "    --limit 100 \\\n",
    "    --output_path ./base_model_results.json\n",
    "\n",
    "print(\"benchmarks completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaDKsydgFxs1",
    "outputId": "e39bdf89-2c4e-4652-8cb4-01e133488c8a"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=\"meta-llama/Meta-Llama-3-8B-Instruct\",peft=\"/content/math_llama3_8b_adapters_ready\",load_in_4bit=True,trust_remote_code=True \\\n",
    "    --tasks gsm8k,minerva_math_algebra,minerva_math_geometry,minerva_math_prealgebra,asdiv \\\n",
    "    --batch_size 1 \\\n",
    "    --limit 100 \\\n",
    "    --output_path ./tuned_model_results.json\n",
    "\n",
    "print(\"benchmarks completed\")\n",
    "'''\n",
    "\n",
    "# trying to run benchmarks for finetuned model this way gives errors related to peft, which is most probably due to disagreement between unsloth and lm-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR1DoDGwXpYf"
   },
   "source": [
    "We will merge the fine tuned model with the base model, which will add the LoRA weights to the base model, this method will increase the size of the model, but we can bypass the peft error by this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440,
     "referenced_widgets": [
      "8b14b5525ea4425bacd9bcfca860e95f",
      "d30aaa1dbafb43d8b17ec09fbb95bac0",
      "5bf5aff0e95f40898abae551c602ee0d",
      "ace8e376ec7e49e2b945e229d48bc628",
      "21c5575865764581902a25b5238d2b33",
      "ec409f49f4ef49ceb95080b488e14809",
      "71af9a3e1a4c45c5b62106b6433a3171",
      "4e06f11e7a6045f3b5b24662a95926cf",
      "cc54fde369ea42fabe5e6b82c36db293",
      "927279861a184343b638a01d1d7e7db8",
      "dd7588a3abd3432a99a333a388453215",
      "87bf6d100f864561bd1e5c83d5a289cc",
      "ef2e59aed440468b8827fb8f2043f8f0",
      "5517dd8576d74059ac45c26241fc9c54",
      "1b0ca785a44f4d149fedbf4c3030bf7e",
      "b82e5236a2e145f6882409294bbbb813",
      "19d9914cca45407ebdbaaaf7663f59c2",
      "a668902f8a304efb845bca0ab4fdf83f",
      "e3e2fca97d804fbc9fdfafb7c650d2e2",
      "3bafe79a92db424bb1e3c1e33fd1b97f",
      "e794318776044b1494af1fb2e0e86ea0",
      "2665dcf315344d1c8a823414e565e6c7",
      "a7185f85e0df499f8d72a92eceef53e8",
      "a571748fbee6426297b97d9ec1c62225",
      "a2c7b4cfd1af4827b6d74e5c958d287e",
      "dd32bf52129a497bb6a2430f8a46ca80",
      "0411b444073b4d34b5e2d3ebdd1aa320",
      "b221250c4d844c6a8968ebbfe454082f",
      "a2a9216119e6416b8bc61fd00f933524",
      "a569b8a9408a44188463ac7c102871d2",
      "42f9b6f9808a4a4c8634b21454fd2c56",
      "a93c5439b41844e5aee779e04120f623",
      "17707312552e4df1970f180b73b3f312",
      "bd117a5248b44a329ef68ce7bfcd7f8b",
      "1b7ac91cd9e44fd5b5218215de7d5866",
      "416532880ac342b1957882836d2d5b6e",
      "3a0497dce535447bb2dc1a11470d4ea3",
      "283b2b60e39a42c88b62db88ebdf6cb5",
      "83f985abe8b44c4c83c86e25ac89aca4",
      "bbb6ac195a4d445fbc4f3341790ea4c0",
      "1a36c93715604a9284dbc6e7b53a3d71",
      "4f642d043ac94bb496d2273bd3af1262",
      "b08b4153ef5446a0a3cff2324e2aacb8",
      "2a37a712f68a45e2b628a2b3e1345a15",
      "460060a2c9df4628b1b5c8cfcc9d1c9b",
      "29deafc2d6c7451098558e0e7ab82de3",
      "79085bc959c944759a01826f6f4a9d46",
      "6236da1b97ee4353b06bf9338b5b01de",
      "28b8378ae58e4563abd10d63d8b75e40",
      "c24ae21b2f9c441c80ec0e48d0a75be0",
      "71a6bef9641c4983aa31ea3b0b6d0582",
      "e6db78d6d2d04476b7199313fae738ea",
      "eb3b46e99b7d42948cea2dcfbaca6601",
      "77add3a2863141318b6552707cd38f71",
      "bb3c4083f8f24e66994c993acb825749"
     ]
    },
    "id": "yOQYHpxo1m0k",
    "outputId": "fb7c7250-89f4-4afb-8b6d-93edc0650e4c"
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    max_seq_length = 2048,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, \"/content/math_llama3_8b_adapters_ready\")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "merged_model.save_pretrained(\"finetuned_math_model\")\n",
    "tokenizer.save_pretrained(\"finetuned_math_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1rZRDoJ1_6S",
    "outputId": "24710303-5a66-4d5e-8e7b-0ebcf35a400c"
   },
   "outputs": [],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=\"/content/finetuned_math_model\",load_in_4bit=True,trust_remote_code=True \\\n",
    "    --tasks gsm8k,minerva_math_algebra,minerva_math_geometry,minerva_math_prealgebra,asdiv \\\n",
    "    --batch_size 1 \\\n",
    "    --limit 100 \\\n",
    "    --output_path ./tuned_model_results.json\n",
    "\n",
    "print(\"benchmarks completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM1_c_1hmWNf"
   },
   "source": [
    "Here are the results of fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sthg-wk_kv97"
   },
   "source": [
    "| Benchmark              | Base Model | Tuned Model |\n",
    "|------------------------|------------|-------------|\n",
    "| minerva_math_prealgebra | 0.39      | 0.49        |\n",
    "| minerva_math_geometry   | 0.11      | 0.16        |\n",
    "| minerva_math_algebra    | 0.32      | 0.35        |\n",
    "|gsm8k                    | 0.73      | 0.71        |\n",
    "| asdiv                   | 0.06      | 0.01        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPQsv66rmaf-"
   },
   "source": [
    "The fine tuned model performs better than the base model on the minerva_math_prealgebra, minerva_math_geometry and minerva_math_algebra benchmarks, which shows that due to fine tuning the model's performance improved on tasks related to algebra and geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uUDbLuBnqMZ"
   },
   "source": [
    "However, the model's performance dropped on gsm8k and asdiv benchmarks. For gsm8k benchmark, due to fine tuning our model became slightly worse, this can be explained by the fact that gsm8k consists mostly of simple maths problems, our fine tuning made the model a specialist on high level maths but decreased the performance slightly on general maths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guwQUojHsMCK"
   },
   "source": [
    "In asdiv benchmark, the benchmark was run in 0-shot mode, so it is very likely that the drop is due to model not giving the answer in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_f4wqrHJiThT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
